<!DOCTYPE html>
<!-- saved from url=(0016)http://localhost -->
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
    
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href="bootstrap_noprint.min.css" rel="stylesheet">
    <link href="font-awesome.min.css" rel="stylesheet">
    <link href="Theme.css" rel="stylesheet">
    
    <script src="jquery.min.js"></script>
    <link href="github-gist.css" rel="stylesheet">
    <script src="highlight.pack.js"></script>
    <script src="preview.js" id="PreviewScript"></script>
</head>
<body>
<div id="MainContent">
    <!-- Markdown Monster Content -->
    <title>Efficient VR and AR Navigation Through Multiperspective Occlusion Management</title>
<h1 id="efficient-vr-and-ar-navigation-through-multiperspective-occlusion-management">Efficient VR and AR Navigation Through Multiperspective Occlusion Management</h1>
<h3 id="m-wu-and-v-popescu">M. Wu and V. Popescu</h3>
<p>[ <a href="papers/ARVR_TVCG17.pdf">paper</a> | <a href="videos/ARVR_TVCG17.mp4">video</a> | <a href="slides/IEEEVR2018_slides.pptx">slides</a> ]</p>
<img src="arvr_teaser.jpg">
<p><em>Top: the user does not have a direct line of sight to the red sphere, which is occluded in the a conventional image; an additional perspective (green frustum) is used to route rays over the occluding buildings (dashed blue line), which disoccludes the red sphere in the resulting multiperspective image. Bottom: the left side corridor is disoccluded by inserting an additional perspective at the portal (red rectangle), which reveals the target (orange ghost).</em></p>
<h5 id="abstract">Abstract</h5>
<p>Immersive navigation in virtual reality (VR) and augmented reality (AR) leverages physical locomotion through pose tracking of the head-mounted display. While this navigation modality is intuitive, regions of interest in the scene may suffer from occlusion and require significant viewpoint translation. Moreover, limited physical space and user mobility need to be taken into consideration. Some regions of interest may require viewpoints that are physically unreachable without less intuitive methods such as walking in-place or redirected walking.</p>
<p>We propose a novel approach for increasing navigation efficiency in VR and AR using multiperspective visualization. Our approach samples occluded regions of interest from additional perspectives, which are integrated seamlessly into the user's perspective. This approach improves navigation efficiency by bringing simultaneously into view multiple regions of interest, allowing the user to explore more while moving less. We have conducted a user study that shows that our method brings significant performance improvement in VR and AR environments, on tasks that include tracking, matching, searching, and ambushing objects of interest.</p>
<h5 id="publication">Publication</h5>
<p>Meng-Lin Wu and Voicu Popescu<br>
Efficient VR and AR Navigation Through Multiperspective Occlusion Management<br>
IEEE Transactions on Visualization and Computer Graphics, vol. 24, no. 12, pp. 3069-3080, 1 Dec. 2018.<br>
URL: <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8123949&amp;isnumber=8511004">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8123949&amp;isnumber=8511004</a></p>

    <!-- End Markdown Monster Content -->
</div>
</body>
</html>